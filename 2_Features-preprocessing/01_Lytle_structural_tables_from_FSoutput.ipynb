{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract structural data \n",
    "### script by Alina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22815298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80d3ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to folder with all subjects data\n",
    "\n",
    "path = '/media/hcs-sci-psy-narun/OpenNEURO_adhd/ds002424-download/'\n",
    "path_out = '/media/hcs-sci-psy-narun/OpenNEURO_adhd/ds002424-download/3T_Structural/'\n",
    "if not os.path.exists(path_out):\n",
    "    os.makedirs(path_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd37276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freesurfer header for indexing\n",
    "\n",
    "#indexes for cortex\n",
    "fs_cort_ind = np.loadtxt('/media/hcs-sci-psy-narun/BackupDataD800/Alina/atlases/destrieux2009_new_header_for_table_WITHOUT_med_wall.txt', \n",
    "                         dtype=str)\n",
    "#indexes for subcortex\n",
    "fs_subc_ind = [\n",
    "    'Left-Accumbens-area',\n",
    "    'Right-Accumbens-area',\n",
    "    'Left-Amygdala',\n",
    "    'Right-Amygdala',\n",
    "    'Brain-Stem',\n",
    "    'Left-Caudate',\n",
    "    'Right-Caudate',\n",
    "    'Left-Cerebellum-Cortex',\n",
    "    'Right-Cerebellum-Cortex',\n",
    "    'Left-VentralDC',\n",
    "    'Right-VentralDC',\n",
    "    'Left-Hippocampus',\n",
    "    'Right-Hippocampus',\n",
    "    'Left-Pallidum',\n",
    "    'Right-Pallidum',\n",
    "    'Left-Putamen',\n",
    "    'Right-Putamen',\n",
    "    'Left-Thalamus-Proper',\n",
    "    'Right-Thalamus-Proper'\n",
    "]\n",
    "#indexes for subcortex like in wb_commands\n",
    "fs_subc_ind_wb = np.loadtxt('/media/hcs-sci-psy-narun/BackupDataD800/Alina/atlases/fs_index_subc.txt', dtype=str)\n",
    "\n",
    "#total brain volume index\n",
    "tot_names = [\n",
    "    'Estimated Total Intracranial Volume',\n",
    "    'Total cortical gray matter volume',\n",
    "    'Subcortical gray matter volume',\n",
    "    'Total cerebral white matter volume',\n",
    "    'Ratio of BrainSegVol to eTIV'\n",
    "]\n",
    "\n",
    "tot_names_ml = [\n",
    "    'FS_IntraCranial_Vol',\n",
    "    'FS_TotCort_GM_Vol',\n",
    "    'FS_SubCort_GM_Vol',\n",
    "    'FS_Tot_WM_Vol',\n",
    "    'FS_BrainSegVol_eTIV_Ratio'    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72b40813",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subject_ID_df  = pd.read_csv(data_dir + \"valid_subj_list.csv\", dtype=str, index_col=0)\n",
    "subject_ID = list(subject_ID_df.iloc[:,0])\n",
    "subjects = [str(x[4:]) for x in subject_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2a775de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#name of files to convert\n",
    "files = ['lh.aparc.a2009s.stats', 'rh.aparc.a2009s.stats', 'aseg.stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cc6f81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert FreeSurfer table into csv-files for each subject for convenience\n",
    "\n",
    "dct1={}\n",
    "dct2={}\n",
    "dct3={}\n",
    "\n",
    "for subject in subjects:\n",
    "    for filename in files:\n",
    "        file = str(path)+ str(subject) +'/T1w/' + str(subject) +'/stats/'+ str(filename)\n",
    "        \n",
    "        if os.path.isfile(file) == True:\n",
    "            #read table\n",
    "            table = pd.DataFrame(np.loadtxt(file, dtype=str))\n",
    "            #read headers\n",
    "            header_names = [l.replace('\\n', '').replace('  ', ' ').replace('# ', '').split(' ')[1:(len(table.columns)+1)] for l in open(file).readlines() if 'ColHeaders' in l]\n",
    "            #rename table\n",
    "            table.columns = header_names[0]\n",
    "            table.index = table['StructName']\n",
    "            table = table.drop('StructName', axis=1)\n",
    "            #save table to dct\n",
    "            if filename == 'lh.aparc.a2009s.stats':\n",
    "                dct1[subject]=table\n",
    "            elif filename == 'rh.aparc.a2009s.stats':\n",
    "                dct2[subject]=table\n",
    "            else:\n",
    "                dct3[subject]=table\n",
    "            \n",
    "        else:\n",
    "            print('not exist')\n",
    "            print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12998a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assemble total brain volumes into separate dictionary\n",
    "dct_tvol = {}\n",
    "for subject in subjects:\n",
    "    file_aseg = open(str(path)+ str(subject) +'/T1w/' + str(subject) +'/stats/'+ str(files[2])).readlines() #read aseg file\n",
    "    tvolvalues = []\n",
    "    for tot in tot_names:\n",
    "        for line in file_aseg:\n",
    "            if tot in line:\n",
    "                tvolvalues+=[line.split(',')[-2]]\n",
    "    dct_tvol[subject] = pd.Series(tvolvalues, index=tot_names_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd4d8ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assemble table by modalities\n",
    "\n",
    "dct_thick = {}\n",
    "dct_area = {}\n",
    "dct_subc = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    #load individual files\n",
    "    df1 = dct1[subject]\n",
    "    df2 = dct2[subject]\n",
    "    df3 = dct3[subject]\n",
    "    #combine lh and rh into one vector\n",
    "    thck_full = np.concatenate([df1['ThickAvg'], df2['ThickAvg']], axis=0)\n",
    "    area_full = np.concatenate([df1['SurfArea'], df2['SurfArea']], axis=0)\n",
    "    #df3.index = df3['StructName']\n",
    "    df3 = df3.reindex(index=fs_subc_ind) #filter to chosen structures\n",
    "    #write to dictionary\n",
    "    dct_thick[subject] = thck_full\n",
    "    dct_area[subject] = area_full\n",
    "    dct_subc[subject] = df3['Volume_mm3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883a6459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if something to short\n",
    "todel = []\n",
    "\n",
    "print('thickness')\n",
    "for key in dct_thick.keys():\n",
    "    if len(dct_thick[key]) < 148:\n",
    "        print('short  ', key, \"  it's length is\", len(dct_thick[key]))\n",
    "        todel += [key]\n",
    "\n",
    "print('areas')        \n",
    "for key in dct_area.keys():\n",
    "    if len(dct_area[key]) < 148:\n",
    "        print('short  ', key, \"  it's length is\", len(dct_area[key]))\n",
    "        todel += [key]\n",
    "        \n",
    "print('subcortex')\n",
    "for key in dct_subc.keys():\n",
    "    if len(dct_subc[key]) < 19:\n",
    "        print('short  ', key, \"  it's length is\", len(dct_subc[key]))\n",
    "        todel += [key]       \n",
    "\n",
    "todel = sorted(set(todel))\n",
    "print(' ')\n",
    "print('need to be removed', todel)\n",
    "\n",
    "\n",
    "#removing this from dictionaries\n",
    "for d in todel:\n",
    "    del dct_thick[d]\n",
    "    del dct_area[d]\n",
    "    del dct_subc[d]\n",
    "    del dct_tvol[d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e3946e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform dct to table\n",
    "df_thick = pd.DataFrame(dct_thick)\n",
    "df_area = pd.DataFrame(dct_area)\n",
    "df_subc = pd.DataFrame(dct_subc)\n",
    "df_tvol = pd.DataFrame(dct_tvol)\n",
    "\n",
    "#change indexes\n",
    "df_thick.index = fs_cort_ind\n",
    "df_area.index = fs_cort_ind\n",
    "df_subc.index = fs_subc_ind_wb\n",
    "\n",
    "#save tables\n",
    "df_thick.T.to_csv(path_out + 'cortical_thickness.csv')\n",
    "df_area.T.to_csv(path_out + 'cortical_area.csv')\n",
    "df_subc.T.to_csv(path_out + 'subcortical_volume.csv')\n",
    "df_tvol.T.to_csv(path_out + 'total_brain_volume.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7d3c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
