{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import libs\n",
    "import numpy as np\n",
    "import plotly\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "import matplotlib.pyplot as plt #to enable plotting within notebook\n",
    "from nilearn import image as nimg\n",
    "from nilearn import plotting \n",
    "from bids.layout import BIDSLayout\n",
    "import bids\n",
    "from matplotlib.pyplot import figure\n",
    "import mpld3\n",
    "import pandas as pd\n",
    "from pathlib import Path   \n",
    "import nibabel as nb \n",
    "import plotly.express as px\n",
    "from nilearn.datasets import fetch_icbm152_brain_gm_mask\n",
    "from nilearn.plotting import plot_roi\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix, run_glm\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from nilearn.glm.contrasts import compute_contrast\n",
    "from nilearn.plotting import plot_contrast_matrix\n",
    "from nilearn.reporting import make_glm_report\n",
    "from nilearn.interfaces.bids import save_glm_to_bids\n",
    "from ordered_set import OrderedSet\n",
    "from nilearn.glm.first_level import first_level_from_bids\n",
    "import pickle\n",
    "import os.path\n",
    "import pathlib\n",
    "import gc\n",
    "from nilearn import image\n",
    "from templateflow import api as tflow\n",
    "from nilearn.maskers import NiftiMasker\n",
    "import traceback\n",
    "import logging\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "import nilearn as nl\n",
    "from nilearn.interfaces.fmriprep import load_confounds\n",
    "import json\n",
    "from nilearn import surface\n",
    "import hcp_utils as hcp\n",
    "from nilearn.glm.contrasts import compute_fixed_effects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # run 1stlevel analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The working directory has been changed!\n"
     ]
    }
   ],
   "source": [
    "##Set path to the data folder\n",
    "os.chdir('/media/hcs-sci-psy-narun/OpenNEURO_adhd/ds002424-download/')\n",
    "print(\"The working directory has been changed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set path & get layout object for later use:\n",
    "data_dir = '/media/hcs-sci-psy-narun/OpenNEURO_adhd/ds002424-download/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### set major parameters\n",
    "\n",
    " #### change task_label accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set variable for each dir task = WM\n",
    "\n",
    "# task_label = ['SLD', 'SSI', 'SSD', 'SLI', 'VLD', 'VSI', 'VSD', 'VLI']\n",
    "space_label = \"MNI152NLin2009cAsym\"\n",
    "derivatives_folder = \"derivatives/fmriprep\"\n",
    "# direction = ['LR', 'RL']\n",
    "#contrast_type = 'story-math'\n",
    "ses = 'T1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### load participants list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subject_ID_df  = pd.read_csv(data_dir + \"valid_subj_list.csv\", dtype=str, index_col=0)\n",
    "subject_ID = list(subject_ID_df.iloc[:,0])\n",
    "subject_ID = [str(x[4:]) for x in subject_ID]\n",
    "# subject_ID.remove('911849')\n",
    "subject_2 = subject_ID[1:2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### function: extract desired confounds\n",
    " #### chooses confound columns & deletes dummy scans\n",
    " #### returns new confound dataframe & list of dummy scans to fix event file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function: extract desired confounds\n",
    "def manage_confounds(original_confs):\n",
    "\n",
    "\n",
    "       cosine = original_confs.filter(regex='^cosine',axis=1)\n",
    "       cosine_regs = list(cosine.columns)\n",
    "       non_steady = original_confs.filter(regex='^non_steady_state',axis=1)\n",
    "       a_comp_cor = ['c_comp_cor_00', 'c_comp_cor_01', 'c_comp_cor_02', 'c_comp_cor_03', 'c_comp_cor_04',\n",
    "                      'w_comp_cor_00', 'w_comp_cor_01', 'w_comp_cor_02', 'w_comp_cor_03', 'w_comp_cor_04']\n",
    "       movement_regs = ['rot_x', 'rot_x_derivative1','rot_y','rot_y_derivative1','rot_z','rot_z_derivative1',\n",
    "                      'trans_x', 'trans_x_derivative1','trans_y', 'trans_y_derivative1','trans_z', 'trans_z_derivative1']\n",
    "\n",
    "       desired_confs = a_comp_cor + cosine_regs + movement_regs\n",
    "\n",
    "\n",
    "       if ~set(desired_confs).issubset(original_confs.columns):\n",
    "              all_confs = original_confs.columns.values.tolist()\n",
    "              mising_confs = list(set(desired_confs) - set(all_confs))\n",
    "              final_confounds = list(OrderedSet(desired_confs) - OrderedSet(mising_confs))\n",
    "       else:\n",
    "              final_confounds = desired_confs\n",
    "       \n",
    "       #get dummy scan rows     \n",
    "       temp = original_confs.isna().any(axis=1)\n",
    "       na_ind = list(temp[temp].index)\n",
    "       dummy = list(np.where(non_steady == 1)[0])\n",
    "       dummy_scans = list(set(na_ind+dummy))\n",
    "       confs_final = original_confs.drop(dummy_scans,axis=0,inplace=False)\n",
    "       confs_final = confs_final.reset_index(drop=True)\n",
    "\n",
    "       confs_final = confs_final.loc[:,final_confounds]\n",
    "       confs_final.insert(confs_final.shape[1],'linear_trend', range(len(dummy_scans), original_confs.shape[0]))\n",
    "\n",
    "       return confs_final, dummy_scans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### function: create & save plots\n",
    " #### plots contrasts maps for effect size and z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function: create & save plots\n",
    "def manage_plots(unparced_z, unparced_eff , sub_id, contrast_t, task_label, output_dir):\n",
    "     surface_zs = nl.plotting.view_surf(hcp.mesh.inflated,\n",
    "     hcp.cortex_data(unparced_z), \n",
    "     bg_map=hcp.mesh.sulc, cmap='bwr')\n",
    "     surface_zs.save_as_html(output_dir + '/sub-%s_ses-%s_task-%s_contrast-%s_z_parcelated_plot.html' %(sub_id, ses, task_label, contrast_t))\n",
    "     surface_eff = nl.plotting.view_surf(hcp.mesh.inflated,\n",
    "     hcp.cortex_data(unparced_eff), \n",
    "     bg_map=hcp.mesh.sulc, cmap='bwr')\n",
    "     surface_eff.save_as_html(output_dir + '/sub-%s_ses-%s_task-%s_contrast-%s_effect_parcelated_plot.html' %(sub_id, ses, task_label, contrast_t))\n",
    "     plt.close('all')\n",
    "     gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### function: prepare events file\n",
    " #### delete faulty scans based on fmriprep confound file and fix timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function: prepare events file:\n",
    "def prepare_events(ind_events,dummy_scans, t_r):\n",
    "    n_dummy = len(dummy_scans)\n",
    "    if n_dummy != 0:\n",
    "        #print(n_dummy)\n",
    "        new_zero = n_dummy * t_r\n",
    "        ind_events['onset'] = ind_events['onset'] - new_zero\n",
    "        invalid_row_ind = np.asarray(ind_events['onset'] < 0).nonzero()\n",
    "        if len(invalid_row_ind[0]) != 0:\n",
    "            del_row = []\n",
    "            for i in invalid_row_ind[0]:\n",
    "                # print(i)\n",
    "                ii=i\n",
    "                new_dur = ind_events.at[ii,'onset']+ind_events.at[ii,'duration']\n",
    "                if new_dur > 0:\n",
    "                    ind_events.at[ii,'onset'] = 0 \n",
    "                    ind_events.at[ii,'duration'] = new_dur\n",
    "                else:\n",
    "                    del_row.append(ii)\n",
    "            ind_events = ind_events.drop(del_row)  \n",
    "    \n",
    "    return  ind_events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_block(ind_events):\n",
    "\n",
    "    ind_events = ind_events[['onset', 'duration', 'trial_type']]\n",
    "    for i in range(len(ind_events) - 2):\n",
    "        if ind_events.at[i, 'trial_type'] == 'no_response':\n",
    "            ind_events.at[i, 'trial_type'] = ind_events.at[i + 3, 'trial_type']\n",
    "    # print(ind_events)\n",
    "    # Identify block starts and ends\n",
    "    ind_events['next_trial_type'] = ind_events['trial_type'].shift(-1)\n",
    "    ind_events['block_end'] = ind_events['trial_type'] != ind_events['next_trial_type']\n",
    "    ind_events['block_start'] = ind_events['block_end'].shift(1, fill_value=True)\n",
    "\n",
    "    # Compute block onsets and ends\n",
    "    block_starts = ind_events[ind_events['block_start']].copy()\n",
    "    block_ends = ind_events[ind_events['block_end']].copy()\n",
    "\n",
    "    # Ensure the same index for merging\n",
    "    block_starts.index = range(len(block_starts))\n",
    "    block_ends.index = range(len(block_ends))\n",
    "\n",
    "    # Merge to get block start and end times\n",
    "    blocks = block_starts.copy()\n",
    "    blocks['block_onset'] = block_starts['onset']\n",
    "    blocks['block_end'] = block_ends['onset'] + block_ends['duration']\n",
    "\n",
    "    # Compute the block duration\n",
    "    blocks['block_duration'] = blocks['block_end'] - blocks['block_onset']\n",
    "\n",
    "    # Select relevant columns\n",
    "    block_df = blocks[['block_onset', 'block_duration', 'trial_type']]\n",
    "    block_df.columns = ['onset', 'duration', 'trial_type']\n",
    "\n",
    "    return block_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### function: prepare contrast matrix:\n",
    " #### defines the desired contrast to be computed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: prepare contrast matrix:\n",
    "def prepare_contrasts(design_mat):\n",
    "    #print(event_design_map.shape)\n",
    "    contrast_matrix = np.eye(design_mat.shape[1])\n",
    "    contrasts = {\n",
    "    column: contrast_matrix[i]\n",
    "    for i, column in enumerate(design_mat.columns)\n",
    "    }\n",
    "    contrasts = {\n",
    "    'twoback':(\n",
    "    contrasts['twoback']\n",
    "    ),\n",
    "    'oneback':(\n",
    "    contrasts['oneback']\n",
    "    ),\n",
    "    'twoback-oneback': (\n",
    "    0.5*contrasts['twoback']\n",
    "    - 0.5*contrasts['oneback']\n",
    "    )\n",
    "    }\n",
    "    return contrasts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### function: mask QC\n",
    " #### plots individualized, data based and fmriprep template masks for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: Reshape, Parcellate \n",
    "def R_P (stat_map):\n",
    "    ##parcelate full\n",
    "    col = np.ones(len(stat_map))\n",
    "    map_2d=np.stack((stat_map,col),axis=1)\n",
    "    map_parc_data = np.transpose(map_2d)\n",
    "\n",
    "    parced_map = hcp.parcellate(map_parc_data, hcp.mmp)\n",
    "    unparced_map = hcp.unparcellate(parced_map[0], hcp.mmp)\n",
    "\n",
    "    return parced_map, unparced_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function:  convert to cifti \n",
    "def convert_to_cifti (stat_map, axes):\n",
    "    ##prepare save as cifti\n",
    "    map = np.reshape(stat_map, (-1, stat_map.shape[0]))\n",
    "    #save contrasts as cifti full\n",
    "    scalar_axis_map = nb.cifti2.ScalarAxis(['stat-map'])  # Takes a list of names, one per row\n",
    "    map_header = nb.Cifti2Header.from_axes([scalar_axis_map, axes[1]])\n",
    "    map_img = nb.Cifti2Image(map, header = map_header, ) #this throws a warning since I don't have a header    \n",
    "                \n",
    "    return map_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_fixed_effects(contrast_arrays, variance_arrays):\n",
    "    # Convert to numpy arrays for element-wise operations\n",
    "    contrast_arrays = np.array(contrast_arrays)\n",
    "    variance_arrays = np.array(variance_arrays)\n",
    "    variance_arrays[variance_arrays == 0] = 1e-9\n",
    "    # Calculate weights as inverse of variances\n",
    "    weights = 1.0 / variance_arrays\n",
    "\n",
    "    # Weighted sum of contrasts\n",
    "    weighted_contrast_sum = np.sum(weights * contrast_arrays, axis=0)\n",
    "\n",
    "    # Sum of weights\n",
    "    sum_of_weights = np.sum(weights, axis=0)\n",
    "\n",
    "    # Combined contrast\n",
    "    combined_contrast = weighted_contrast_sum / sum_of_weights\n",
    "\n",
    "    # Combined variance\n",
    "    combined_variance = 1.0 / sum_of_weights\n",
    "\n",
    "    return combined_contrast, combined_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### function: dir GLM and extract contrasts\n",
    " #### main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function: run GLM and extract contrasts\n",
    "def surf_contrast(iter, sub_label, data_dir, output_dir, temp_img, masker):\n",
    "    try:\n",
    "        warnings.filterwarnings(action='ignore')\n",
    "        # map_dict = {1: \"oneback\", 2:\"twoback\"}\n",
    "        path = (output_dir+'sub-{}'.format(sub_label))\n",
    "        #print(path)\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "        #plt.ioff()\n",
    "\n",
    "\n",
    "        # set up lists for averaging across direction\n",
    "        z_data = []\n",
    "        eff_data = []\n",
    "        v_data = []\n",
    "        print('start:'+sub_label)\n",
    "\n",
    "        task_labels = ['SLD', 'SSI', 'SSD', 'SLI']# verbal = ['VLD', 'VSI', 'VSD', 'VLI']\n",
    "        for task_label in task_labels:\n",
    "            json_file = data_dir + 'derivatives/fmriprep/sub-%s/ses-T1/func/sub-%s_ses-T1_task-%s_space-fsLR_den-91k_bold.json' %(sub_label,sub_label, task_label)\n",
    "            if os.path.isfile(json_file):\n",
    "                with open(json_file, 'r') as f:\n",
    "                    t_r = json.load(f)['RepetitionTime']\n",
    "                \n",
    "                fmriprep_bold = (data_dir + 'derivatives/fmriprep/sub-%s/ses-T1/func/sub-%s_ses-T1_task-%s_space-fsLR_den-91k_bold.dtseries.nii' %(sub_label, sub_label, task_label))\n",
    "                eve_dir = (data_dir + 'sub-%s/ses-T1/func/sub-%s_ses-T1_task-%s_events.tsv' %(sub_label, sub_label, task_label))\n",
    "                conf_dir = (data_dir + 'derivatives/fmriprep/sub-%s/ses-T1/func/sub-%s_ses-T1_task-%s_desc-confounds_timeseries.tsv' %(sub_label, sub_label, task_label))\n",
    "\n",
    "                events = pd.read_csv(eve_dir , sep='\\t')\n",
    "                confounds = pd.read_csv(conf_dir, sep='\\t')\n",
    "                #func_mni_img = nimg.load_img(fmriprep_bold)\n",
    "\n",
    "                # call confounds function:\n",
    "                [confounds_final, dummy_scans] = manage_confounds(confounds)\n",
    "\n",
    "                # confounds_final = confounds_final.reset_index(drop=True)\n",
    "\n",
    "                # calculate frametimes using confounds file n_rows and T_R\n",
    "                frame_times = (np.arange(confounds_final.shape[0]) * t_r)# + (t_r/2)\n",
    "\n",
    "                # call prepare event file function\n",
    "                ind_events = events.copy()\n",
    "                # fix events names\n",
    "                ind_events = ind_events.replace(regex=['1-'],value='one')\n",
    "                ind_events = ind_events.replace(regex=['2-'],value='two')\n",
    "                # ind_events['trial_type']= ind_events['trial_type'].map(map_dict)\n",
    "                # print(ind_events.loc[:,'trial_type'])\n",
    "                ind_events = to_block(ind_events)\n",
    "\n",
    "                ind_events = prepare_events(ind_events, dummy_scans, t_r)\n",
    "                # print(ind_events.loc[:,'trial_type'])\n",
    "                # ind_events = ind_events.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "                # save events file\n",
    "                ind_events.to_csv(output_dir + \n",
    "                                'sub-%s/sub-%s_ses-%s_task-%s_events.tsv' %(sub_label, sub_label, ses, task_label), sep='\\t')\n",
    "                confounds_final.to_csv(output_dir + \n",
    "                                'sub-%s/sub-%s_ses-%s_task-%s_confs.tsv' %(sub_label, sub_label, ses, task_label), sep='\\t')\n",
    "                # smoothed_img = image.smooth_img(ind_image, 6)\n",
    "\n",
    "                design_matrix = make_first_level_design_matrix(frame_times = frame_times, \n",
    "                                                                    events=ind_events, hrf_model='spm', \n",
    "                                                                    add_regs=confounds_final,\n",
    "                                                                    drift_model= None, #drift_order=2, #high_pass=1/128, \n",
    "                                                                    # #fir_delays=[0], #add_reg_names=None, #min_onset=-24, #oversampling=50\n",
    "                )\n",
    "                # # add the linear trend column to design matrix (to match it with xcp-d)\n",
    "                # end_col = design_matrix.shape[1]\n",
    "                # design_matrix.insert(end_col-1, 'linear_trend', range(len(dummy_scans), confounds.shape[0]))\n",
    "                # design_matrix.add_poly(order=1, include_lower=True)\n",
    "                # design_matrix.add_poly(order=2, include_lower=True)\n",
    "\n",
    "                #design_matrix.to_csv(data_dir + 'derivatives/nilearn_glm/sub-%s_task-%s_dir-%s_design' % (model.subject_label, task_label, direction[dir]))\n",
    "                del confounds, events\n",
    "\n",
    "                # load image file and remove dummy scans:\n",
    "\n",
    "                cifti = nb.load(fmriprep_bold)\n",
    "                cifti_data = cifti.get_fdata()\n",
    "                cifti_hdr = cifti.header\n",
    "                nifti_hdr = cifti.nifti_header\n",
    "                axes = [cifti_hdr.get_axis(i) for i in range(cifti.ndim)]\n",
    "                cifti_data = cifti_data[len(dummy_scans):,:]\n",
    "                del cifti\n",
    "                cifti_data = nl.signal.clean(cifti_data, detrend=False, standardize='zscore_sample', confounds=None, standardize_confounds=False,\n",
    "                                            filter=False, low_pass=None, high_pass=None, t_r=t_r, ensure_finite=False )\n",
    "                # fit the model \n",
    "                labels, estimates = run_glm(cifti_data, design_matrix.values, noise_model='ols')\n",
    "                \n",
    "                design_plot = plotting.plot_design_matrix(design_matrix)\n",
    "                design_plot.figure.savefig(path + '/sub-%s_ses-%s_task-%s_design.svg' %(sub_label, ses, task_label))\n",
    "                design_matrix.to_csv(path + '/sub-%s_ses-%s_task-%s_design.tsv' %(sub_label, ses, task_label), sep='\\t')\n",
    "                \n",
    "                del cifti_data\n",
    "                # call contrast matrix function:\n",
    "                contrasts = prepare_contrasts(design_matrix)\n",
    "                #print(\"contrast created\")\n",
    "                # compute and generate contrasts (betas and z score)\n",
    "                for index, (contrast_id, contrast_val) in enumerate(contrasts.items()):\n",
    "                    contrast_map = compute_contrast(labels, estimates, contrast_val, stat_type='t')\n",
    "                    # We present the Z-transform of the t map.\n",
    "                    zmap = contrast_map.z_score()\n",
    "                    effect_size = contrast_map.effect_size()[0]\n",
    "                    variance = contrast_map.effect_variance()\n",
    "\n",
    "\n",
    "                    #plot contrast design\n",
    "                    contrast_plot = plot_contrast_matrix(\n",
    "                    contrast_val,\n",
    "                    design_matrix,\n",
    "                    colorbar=True,\n",
    "                    )\n",
    "                    contrast_plot.set_xlabel(contrast_id)\n",
    "                    contrast_plot.figure.set_figheight(2)\n",
    "                    contrast_plot.figure.set_tight_layout(True)\n",
    "                    contrast_plot.figure.savefig(path + '/sub-%s_ses-%s_task-%s_contrast-%s_design.svg' %(sub_label, ses, task_label, contrast_id))\n",
    "                    \n",
    "                    parced_z, unparced_z = R_P(zmap)\n",
    "                    parced_eff, unparced_eff = R_P(zmap)\n",
    "\n",
    "                    headers = list(hcp.mmp.labels.values())[1:]\n",
    "                    pd.DataFrame(parced_z, columns = headers).to_csv(path + '/sub-%s_ses-%s_task-%s_contrast-%s_z_parcelations.tsv' %(sub_label, ses, task_label, contrast_id), sep='\\t')\n",
    "                    pd.DataFrame(parced_eff, columns = headers).to_csv(path + '/sub-%s_ses-%s_task-%s_contrast-%s_effect_parcelations.tsv' %(sub_label, ses, task_label, contrast_id), sep='\\t')\n",
    "\n",
    "                    var_img = convert_to_cifti(variance, axes)\n",
    "\n",
    "                    z_img = convert_to_cifti(zmap, axes)\n",
    "                    z_img.to_filename(path + '/sub-%s_ses-%s_task-%s_contrast-%s_space-fsLR_den-91k_stat-z.dtseries.nii' %(sub_label, ses, task_label, contrast_id))\n",
    "                    eff_img = convert_to_cifti(effect_size, axes)\n",
    "                    eff_img.to_filename(path + '/sub-%s_ses-%s_task-%s_contrast-%s_space-fsLR_den-91k_stat-effect.dtseries.nii' %(sub_label, ses, task_label, contrast_id))\n",
    "                    unp_z_img = convert_to_cifti(unparced_z, axes)\n",
    "                    unp_z_img.to_filename(path + '/sub-%s_ses-%s_task-%s_contrast-%s_space-fsLR_den-91k_stat-z_parcellated.dtseries.nii' %(sub_label, ses, task_label, contrast_id))\n",
    "                    unp_eff_img = convert_to_cifti(unparced_eff, axes)\n",
    "                    unp_eff_img.to_filename(path + '/sub-%s_ses-%s_task-%s_contrast-%s_space-fsLR_den-91k_stat-effect_parcellated.dtseries.nii' %(sub_label, ses, task_label, contrast_id))\n",
    "                    v_data.append(variance)\n",
    "                    z_data.append(zmap)\n",
    "                    eff_data.append(effect_size)\n",
    "                    # plot contrast maps for each direction\n",
    "                    # manage_plots(unparced_z, unparced_eff, sub_label, contrast_id, task_label, path)\n",
    "\n",
    "                    #print(\"plots created\")\n",
    "\n",
    "                    plt.close('all')\n",
    "\n",
    "        plt.close('all')\n",
    "\n",
    "        r4= int(len(z_data)/4)\n",
    "        dirM = 'spatial' # verbal \n",
    "\n",
    "        for ind , contr_id in enumerate(contrasts.keys()):\n",
    "            # combine directions and calculate mean \n",
    "\n",
    "            # Compute fixed effects\n",
    "            mean_z_arr, var_map_z = combine_fixed_effects([z_data[ind],z_data[ind+r4],z_data[ind+r4*2],z_data[ind+r4*3]], [v_data[ind],v_data[ind+r4],v_data[ind+r4*2],v_data[ind+r4*3]])  \n",
    "            mean_effect_arr, var_map_eff = combine_fixed_effects([eff_data[ind],eff_data[ind+r4],eff_data[ind+r4*2],eff_data[ind+r4*3]], [v_data[ind],v_data[ind+r4],v_data[ind+r4*2],v_data[ind+r4*3]])   \n",
    "            parced_Mz, unparced_Mz = R_P(mean_z_arr)\n",
    "            parced_Meff, unparced_Meff = R_P(mean_effect_arr)\n",
    "\n",
    "            pd.DataFrame(parced_Mz, columns = headers).to_csv(path + '/sub-%s_task-%s_contrast-%s_z_parcelations.tsv' %(sub_label, dirM, contr_id), sep='\\t')\n",
    "            pd.DataFrame(parced_Meff, columns = headers).to_csv(path + '/sub-%s_task-%s_contrast-%s_effect_parcelations.tsv' %(sub_label, dirM, contr_id), sep='\\t')\n",
    "\n",
    "            #print(\"mean created\")\n",
    "            mean_z_img = convert_to_cifti(mean_z_arr, axes)\n",
    "            mean_z_img.to_filename(path + '/sub-%s_task-%s_contrast-%s_space-fsLR_den-91k_stat-z.dtseries.nii' %(sub_label, dirM, contr_id))\n",
    "            mean_eff_img = convert_to_cifti(mean_effect_arr, axes)\n",
    "            mean_eff_img.to_filename(path + '/sub-%s_task-%s_contrast-%s_space-fsLR_den-91k_stat-effect.dtseries.nii' %(sub_label, dirM, contr_id))\n",
    "\n",
    "            unp_Mz_img = convert_to_cifti(unparced_Mz, axes)\n",
    "            unp_Mz_img.to_filename(path + '/sub-%s_task-%s_contrast-%s_space-fsLR_den-91k_stat-z_parcellated.dtseries.nii' %(sub_label, dirM, contr_id))\n",
    "            unp_eff_img = convert_to_cifti(unparced_Meff, axes)\n",
    "            unp_eff_img.to_filename(path + '/sub-%s_task-%s_contrast-%s_space-fsLR_den-91k_stat-effect_parcellated.dtseries.nii' %(sub_label, dirM, contr_id))\n",
    "\n",
    "            manage_plots(unparced_Mz, unparced_Meff, sub_label, contr_id, dirM, path)\n",
    "        #     plt.close('all')\n",
    "\n",
    "        print('done:'+sub_label)\n",
    "        \n",
    "        gc.collect()\n",
    "    except Exception as e:\n",
    "        #error.append(sub_label)\n",
    "        logging.error(traceback.format_exc())\n",
    "    # except ValueError:\n",
    "    #     print(model.subject_label +'raised value error')\n",
    "    # except TypeError:\n",
    "    #     print(model.subject_label +'raised type error')\n",
    "    # except MemoryError:\n",
    "    #     print(model.subject_label +'raised memory error')    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### run in parallel for all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:02\n",
      "start:05\n",
      "start:04\n",
      "start:08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_10757/2240966615.py\", line 154, in surf_contrast\n",
      "UnboundLocalError: cannot access local variable 'contrasts' where it is not associated with a value\n",
      "\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:09\n",
      "start:07\n",
      "start:31\n",
      "start:03\n",
      "start:06\n",
      "start:10\n",
      "start:22\n",
      "start:13\n",
      "start:11\n",
      "start:15\n",
      "start:14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:12\n",
      "start:23\n",
      "start:18\n",
      "start:17\n",
      "start:19\n",
      "start:28\n",
      "start:21\n",
      "start:30\n",
      "start:20\n",
      "start:26\n",
      "start:24start:25\n",
      "\n",
      "start:27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_10757/2240966615.py\", line 154, in surf_contrast\n",
      "UnboundLocalError: cannot access local variable 'contrasts' where it is not associated with a value\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_10757/2240966615.py\", line 154, in surf_contrast\n",
      "UnboundLocalError: cannot access local variable 'contrasts' where it is not associated with a value\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:16\n",
      "start:29\n",
      "start:32\n",
      "start:33\n",
      "done:07\n",
      "start:34\n",
      "start:35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_10757/2240966615.py\", line 154, in surf_contrast\n",
      "UnboundLocalError: cannot access local variable 'contrasts' where it is not associated with a value\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done:02\n",
      "start:36\n",
      "done:01\n",
      "start:37\n",
      "done:22\n",
      "start:38\n",
      "done:30\n",
      "done:18\n",
      "start:39\n",
      "done:06\n",
      "done:04\n",
      "start:40\n",
      "start:41\n",
      "start:42\n",
      "start:43\n",
      "start:44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_10757/2240966615.py\", line 154, in surf_contrast\n",
      "UnboundLocalError: cannot access local variable 'contrasts' where it is not associated with a value\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_10757/2240966615.py\", line 154, in surf_contrast\n",
      "UnboundLocalError: cannot access local variable 'contrasts' where it is not associated with a value\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done:28\n",
      "start:45\n",
      "start:46\n",
      "done:31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_10757/2240966615.py\", line 154, in surf_contrast\n",
      "UnboundLocalError: cannot access local variable 'contrasts' where it is not associated with a value\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done:15\n",
      "done:27\n",
      "start:47\n",
      "start:48\n",
      "start:49\n",
      "done:13\n",
      "start:50\n",
      "done:29\n",
      "start:51\n",
      "done:21\n",
      "start:52\n",
      "done:23\n",
      "done:20\n",
      "start:53\n",
      "done:14\n",
      "start:54\n",
      "done:16\n",
      "start:55\n",
      "start:56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_10757/2240966615.py\", line 154, in surf_contrast\n",
      "UnboundLocalError: cannot access local variable 'contrasts' where it is not associated with a value\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done:33\n",
      "done:11\n",
      "start:57\n",
      "done:26\n",
      "done:09\n",
      "start:58\n",
      "done:03\n",
      "start:59\n",
      "done:08\n",
      "start:60\n",
      "done:32\n",
      "start:61\n",
      "done:10\n",
      "start:62\n",
      "start:63\n",
      "done:17\n",
      "start:64\n",
      "start:65\n",
      "start:66\n",
      "start:67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_10757/2240966615.py\", line 154, in surf_contrast\n",
      "UnboundLocalError: cannot access local variable 'contrasts' where it is not associated with a value\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_10757/2240966615.py\", line 154, in surf_contrast\n",
      "UnboundLocalError: cannot access local variable 'contrasts' where it is not associated with a value\n",
      "\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_10757/2240966615.py\", line 154, in surf_contrast\n",
      "UnboundLocalError: cannot access local variable 'contrasts' where it is not associated with a value\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:68\n",
      "done:19\n",
      "start:69\n",
      "start:70\n",
      "start:71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_10757/2240966615.py\", line 154, in surf_contrast\n",
      "UnboundLocalError: cannot access local variable 'contrasts' where it is not associated with a value\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done:12\n",
      "start:72\n",
      "done:35\n",
      "start:73\n",
      "done:50\n",
      "start:74\n",
      "done:36\n",
      "start:75\n",
      "done:59\n",
      "done:52\n",
      "start:76\n",
      "start:77\n",
      "done:37\n",
      "start:78\n",
      "done:38\n",
      "start:79\n",
      "done:41\n",
      "done:39\n",
      "done:47\n",
      "done:46\n",
      "done:51\n",
      "done:48\n",
      "done:49\n",
      "done:57\n",
      "done:40\n",
      "done:60\n",
      "done:44\n",
      "done:58\n",
      "done:54\n",
      "done:67\n",
      "done:68\n",
      "done:56\n",
      "done:53\n",
      "done:61\n",
      "done:69\n",
      "done:71\n",
      "done:66\n",
      "done:63\n",
      "done:73\n",
      "done:72\n",
      "done:75\n",
      "done:74\n",
      "done:77\n",
      "done:76\n",
      "done:78\n",
      "done:79\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## run parallel\n",
    "import warnings\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "from joblib import parallel_backend\n",
    "from joblib import Memory\n",
    "\n",
    "from joblib import Memory\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "#plt.ioff()\n",
    "output_dir = data_dir + \"derivatives/nilearn_glm/surf_WM_std/\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "Parallel(n_jobs=30)(delayed(surf_contrast)(iter, subject_label, data_dir, output_dir,  mni_gm , masker) for iter, subject_label in enumerate(subject_ID))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### get completed and incompleted and erroneous subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/media/hcs-sci-psy-narun/OpenNEURO_adhd/scripts/Opadhd_surf_contrasts_LR-RL_WM_parcelated_notsmoothed_standardized.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/hcs-sci-psy-narun/OpenNEURO_adhd/scripts/Opadhd_surf_contrasts_LR-RL_WM_parcelated_notsmoothed_standardized.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m output_dir \u001b[39m=\u001b[39m output_dir\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/hcs-sci-psy-narun/OpenNEURO_adhd/scripts/Opadhd_surf_contrasts_LR-RL_WM_parcelated_notsmoothed_standardized.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m incomplete \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/hcs-sci-psy-narun/OpenNEURO_adhd/scripts/Opadhd_surf_contrasts_LR-RL_WM_parcelated_notsmoothed_standardized.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m nonexist \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_dir' is not defined"
     ]
    }
   ],
   "source": [
    "output_dir = output_dir\n",
    "\n",
    "incomplete = []\n",
    "nonexist = []\n",
    "folder_is = []\n",
    "for id in subject_ID:\n",
    "    #print(id)\n",
    "    diris = os.path.isdir(output_dir + 'sub-%s' %id)\n",
    "    folder_is.append(diris)\n",
    "    if diris == False:\n",
    "        nonexist.append(id)\n",
    "    else:\n",
    "        completed = os.path.isfile(output_dir +'sub-%s/sub-%s_task-WM_dir-mean_contrast-twobk-zerobk_space-fsLR_den-91k_stat-effect_parcellated.dtseries.nii' %(id , id))\n",
    "        if completed == False:\n",
    "            incomplete.append(id)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### number of :\n",
    " #### completed , all, missing file , incompltete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(subject_ID), len(nonexist), len(incomplete))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### save lists of completed and error subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(nonexist).to_csv(output_dir + 'error_subjects')\n",
    "pd.DataFrame(incomplete).to_csv(output_dir + 'incompleted_subjects')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nilearn_py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
