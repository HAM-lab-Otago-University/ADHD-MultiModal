{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance - calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "import warnings\n",
    "# from datetime import date, datetime\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr, norm\n",
    "import scipy.stats as st\n",
    "from scipy.stats import zscore as  zscore\n",
    "from joblib import Parallel, delayed\n",
    "# from multiprocessing import Manager\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "import gc\n",
    "import traceback\n",
    "import logging\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets and models\n",
    "targ_list = ['total_','cryst_','fluid_']\n",
    "model_list = ['eN2','pls','eN1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directories\n",
    "root_dir ='/media/hcs-sci-psy-narun/ABCC/fmriresults01/derivatives/ML_Tables/nesi_outputs/std_applicability/'\n",
    "plot_dir = root_dir + '/prediction_plots/'\n",
    "tables_path ='/media/hcs-sci-psy-narun/ABCC/fmriresults01/derivatives/ML_Tables/'\n",
    "if not os.path.isdir(root_dir):\n",
    "    os.mkdir(root_dir) \n",
    "if not os.path.isdir(plot_dir):\n",
    "    os.mkdir(plot_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run bootstrap on correlations (observed, predicted)\n",
    "def bootstrap_corr_ci(x, y, n_bootstraps=1000, alpha=0.05):\n",
    "    boot_corrs = []\n",
    "    n = len(x)\n",
    "    \n",
    "    for _ in range(n_bootstraps):\n",
    "        # Resample with replacement\n",
    "        indices = np.random.choice(np.arange(n), size=n, replace=True)\n",
    "        boot_corrs.append(pearsonr(x[indices], y[indices])[0])\n",
    "        \n",
    "    # Confidence intervals from percentiles\n",
    "    lower = np.percentile(boot_corrs, 100 * (alpha / 2))\n",
    "    upper = np.percentile(boot_corrs, 100 * (1 - alpha / 2))\n",
    "    \n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABCD NIH toolbox cognitive scores for each group \n",
    "T1 = pd.read_csv(tables_path+'cog_tables/cog_t1.csv', index_col=0)\n",
    "T1.index = T1.index.str.replace('_', '')\n",
    "T2 = pd.read_csv(tables_path+'cog_tables/cog_t2.csv', index_col=0)\n",
    "T2.index = T2.index.str.replace('_', '')\n",
    "T3 = pd.read_csv(tables_path+'cog_tables/cog_t3.csv', index_col=0)\n",
    "T3.index = T3.index.str.replace('_', '')\n",
    "T4 = pd.read_csv(tables_path+'cog_tables/cog_t4.csv', index_col=0)\n",
    "T4.index = T4.index.str.replace('_', '')\n",
    "non = pd.read_csv(tables_path+'cog_tables/cog_non.csv', index_col=0)\n",
    "non.index = non.index.str.replace('_', '')\n",
    "All = pd.read_csv(tables_path+'cog_tables/cog_all.csv', index_col=0)\n",
    "All.index = All.index.str.replace('_', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate test performance measures and save them\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ABCD predicition performance \n",
    "def cal_cor1(group, all_predicted, key, i, col):\n",
    "    tar = targ[0:4]\n",
    "    group_pred_ind = list(set(all_predicted.index).intersection(group.dropna().index))\n",
    "    true_val = yt_all.loc[group_pred_ind].values.flatten()\n",
    "    pre_val = all_predicted.loc[group_pred_ind].values.flatten()\n",
    "    p_corr, _ = pearsonr(true_val, pre_val)\n",
    "    r2 = r2_score(true_val, pre_val)\n",
    "    rmse = np.sqrt(mean_squared_error(true_val, pre_val))\n",
    "    mae = mean_absolute_error(true_val, pre_val)\n",
    "    # prediction_results = prediction_results.append(pd.Series(), ignore_index=True)\n",
    "    new_row[0] = key\n",
    "    new_row[col + 1] = round(p_corr, 3)\n",
    "    new_row[col + 2] = round(r2, 3)\n",
    "    new_row[col + 3] = round(rmse, 3)\n",
    "    new_row[col + 4] = round(mae, 3)\n",
    "    plot_obj = [true_val, pre_val]\n",
    "    boot_obj = [yt_all.loc[group_pred_ind], all_predicted.loc[group_pred_ind]]\n",
    "\n",
    "    # Calculate confidence interval for the correlation coefficient\n",
    "    # fisher_z = np.arctanh(p_corr)\n",
    "    # se = 1 / np.sqrt(len(group_pred_ind) - 3)\n",
    "    # z_score = norm.ppf(1 - (1 - 0.95) / 2)\n",
    "    # ci_lower_z = fisher_z - z_score * se\n",
    "    # ci_upper_z = fisher_z + z_score * se\n",
    "    # ci_lower = np.tanh(ci_lower_z)\n",
    "    # ci_upper = np.tanh(ci_upper_z)\n",
    "    # Calculate bootstrap confidence intervals\n",
    "    ci_lower, ci_upper = bootstrap_corr_ci(true_val, pre_val)\n",
    "\n",
    "    # plt.show()\n",
    "    plt.close('all')\n",
    "    return [plot_obj, r2, p_corr, len(group_pred_ind), boot_obj, [ci_lower, ci_upper]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main: Single - ABCD - ABCC\n",
    "#Load all test folds, calculate predicitve performance, save.\n",
    "root_dir = '/media/hcs-sci-psy-narun/ABCC/fmriresults01/derivatives/ML_Tables/nesi_outputs/std_applicability/'\n",
    "targ_list = ['cryst_','fluid_']#,,'cryst_','fluid_''total_'\n",
    "model_list = ['mnct_enet1'] #'eN1', 'pls','pls','abcd_eN1', 'abcd_pls''eN1',, 'arcn_pls'\n",
    "for model in model_list:\n",
    "      for targ in targ_list:\n",
    "            model_outs = joblib.load(root_dir + targ + model + '.joblib')\n",
    "            # model_outs = joblib.load(root_dir + targ + 'abcd_' + model + '_std.joblib')\n",
    "            \n",
    "            prediction_results = pd.DataFrame(columns=['', 'Tier1','Tier1','Tier1','Tier1','Tier2','Tier2','Tier2','Tier2',\n",
    "                                                                                                      'Tier3', 'Tier3', 'Tier3','Tier3', 'Tier4','Tier4', 'Tier4','Tier4', \n",
    "                                                                                                      'non-ADHD','non-ADHD','non-ADHD','non-ADHD', 'All', 'All','All','All'])\n",
    "            measure_list = ['Models','r', 'R2', 'MAE', 'RMSE', 'r', 'R2', 'MAE', 'RMSE', 'r', 'R2', 'MAE', 'RMSE','r', 'R2', 'MAE', 'RMSE','r', 'R2', 'MAE', 'RMSE','r', 'R2', 'MAE', 'RMSE']\n",
    "            prediction_results.loc[0] = measure_list\n",
    "            moda_yps = {'smri': {}, 'conn': {}, 'cntr': {}, 'gtfc': {} }#, 'tang': {}\n",
    "            moda_yts = {'smri': {}, 'conn': {}, 'cntr': {}, 'gtfc': {}}#, 'tang': {}\n",
    "            corr_results = {'smri': {}, 'conn': {}, 'cntr': {}, 'gtfc': {} }#, 'tang': {}\n",
    "            # moda_yps = {'abcd_rsmri': {}, 'abcd_cntr': {} }#, 'tang': {}\n",
    "            # moda_yts = {'abcd_rsmri': {}, 'abcd_cntr': {} }#, 'tang': {}\n",
    "            # corr_results = {'abcd_rsmri': {}, 'abcd_cntr': {} }#, 'tang': {}\n",
    "            plot_dict = {}\n",
    "            for fold, sets_dict in model_outs.items():\n",
    "                    for set_n, set_dict in sets_dict.items():\n",
    "                        for feature_n, feature_dict in set_dict.items():\n",
    "                                if feature_n not in moda_yps[set_n]:\n",
    "                                    moda_yps[set_n][feature_n] = []\n",
    "                                    moda_yts[set_n][feature_n] = []\n",
    "                                moda_yps[set_n][feature_n].append(feature_dict['data']['yptest'])\n",
    "                                moda_yts[set_n][feature_n].append(feature_dict['data']['yttest'])\n",
    "\n",
    "            for set_name , moda in moda_yps.items():\n",
    "                for iter, (f_name, y) in enumerate(moda.items()):\n",
    "                        yp_all = pd.concat(y, axis=0)\n",
    "                        yt_all = pd.concat(moda_yts[set_name][f_name], axis=0)\n",
    "                        new_row = pd.Series([None] * len(prediction_results.columns), index=prediction_results.columns)\n",
    "                        corr_results[set_name][f_name] = {}\n",
    "                        corr_results[set_name][f_name]['Tier1'] = cal_cor1(T1, yp_all, f_name, iter+1, 0)\n",
    "                        corr_results[set_name][f_name]['Tier2']  = cal_cor1(T2, yp_all, f_name, iter+1, 4)\n",
    "                        corr_results[set_name][f_name]['Tier3']  = cal_cor1( T3, yp_all, f_name, iter+1,  8)\n",
    "                        corr_results[set_name][f_name]['Tier4']  = cal_cor1(T4, yp_all, f_name, iter+1,  12)\n",
    "                        corr_results[set_name][f_name]['non-ADHD']  = cal_cor1(non, yp_all, f_name, iter+1, 16)\n",
    "                        corr_results[set_name][f_name]['All']  = cal_cor1(All, yp_all, f_name, iter+1, 20)\n",
    "                        reshaped_row = new_row.values.reshape(1, -1)  # Reshape to a single row\n",
    "                        reshaped_row_df = pd.DataFrame(reshaped_row, columns=prediction_results.columns)\n",
    "                        prediction_results = pd.concat([prediction_results, reshaped_row_df], ignore_index=True)\n",
    "                        # prediction_results = prediction_results.append(new_row, ignore_index=True)\n",
    "                        #pd.concat([prediction_results, pd.DataFrame([new_row], columns=prediction_results.columns)], ignore_index=True)\n",
    "            prediction_results.to_csv(plot_dir  + targ + model + '_predictive_ability.csv')\n",
    "            joblib.dump(corr_results, plot_dir  + targ + model + '_corr_res.joblib')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main: Single - ABCD - ABCD\n",
    "\n",
    "root_dir = '/media/hcs-sci-psy-narun/ABCC/fmriresults01/derivatives/ML_Tables/nesi_outputs/std_applicability/'\n",
    "targ_list = ['total_','cryst_','fluid_']#,,'cryst_','fluid_'\n",
    "model_list = ['eN1', 'pls'] #'eN1', 'pls','pls','abcd_eN1', 'abcd_pls'\n",
    "for model in model_list:\n",
    "      for targ in targ_list:\n",
    "            # model_outs = joblib.load(root_dir + targ + model + '_std.joblib')\n",
    "            model_outs = joblib.load(root_dir + targ + 'abcd_' + model + '_std.joblib')\n",
    "            \n",
    "            prediction_results = pd.DataFrame(columns=['', 'Tier1','Tier1','Tier1','Tier1','Tier2','Tier2','Tier2','Tier2',\n",
    "                                                                                                      'Tier3', 'Tier3', 'Tier3','Tier3', 'Tier4','Tier4', 'Tier4','Tier4', \n",
    "                                                                                                      'non-ADHD','non-ADHD','non-ADHD','non-ADHD', 'All', 'All','All','All'])\n",
    "            measure_list = ['Models','r', 'R2', 'MAE', 'RMSE', 'r', 'R2', 'MAE', 'RMSE', 'r', 'R2', 'MAE', 'RMSE','r', 'R2', 'MAE', 'RMSE','r', 'R2', 'MAE', 'RMSE','r', 'R2', 'MAE', 'RMSE']\n",
    "            prediction_results.loc[0] = measure_list\n",
    "            # moda_yps = {'smri': {}, 'conn': {}, 'cntr': {}, 'gtfc': {} }#, 'tang': {}\n",
    "            # moda_yts = {'smri': {}, 'conn': {}, 'cntr': {}, 'gtfc': {}}#, 'tang': {}\n",
    "            # corr_results = {'smri': {}, 'conn': {}, 'cntr': {}, 'gtfc': {} }#, 'tang': {}\n",
    "            moda_yps = {'abcd_rsmri': {}, 'abcd_cntr': {} }#, 'tang': {}\n",
    "            moda_yts = {'abcd_rsmri': {}, 'abcd_cntr': {} }#, 'tang': {}\n",
    "            corr_results = {'abcd_rsmri': {}, 'abcd_cntr': {} }#, 'tang': {}\n",
    "            plot_dict = {}\n",
    "            for fold, sets_dict in model_outs.items():\n",
    "                    for set_n, set_dict in sets_dict.items():\n",
    "                        for feature_n, feature_dict in set_dict.items():\n",
    "                                if feature_n not in moda_yps[set_n]:\n",
    "                                    moda_yps[set_n][feature_n] = []\n",
    "                                    moda_yts[set_n][feature_n] = []\n",
    "                                moda_yps[set_n][feature_n].append(feature_dict['data']['yptest'])\n",
    "                                moda_yts[set_n][feature_n].append(feature_dict['data']['yttest'])\n",
    "\n",
    "            for set_name , moda in moda_yps.items():\n",
    "                for iter, (f_name, y) in enumerate(moda.items()):\n",
    "                        yp_all = pd.concat(y, axis=0)\n",
    "                        yt_all = pd.concat(moda_yts[set_name][f_name], axis=0)\n",
    "                        new_row = pd.Series([None] * len(prediction_results.columns), index=prediction_results.columns)\n",
    "                        corr_results[set_name][f_name] = {}\n",
    "                        corr_results[set_name][f_name]['Tier1'] = cal_cor1(T1, yp_all, f_name, iter+1, 0)\n",
    "                        corr_results[set_name][f_name]['Tier2']  = cal_cor1(T2, yp_all, f_name, iter+1, 4)\n",
    "                        corr_results[set_name][f_name]['Tier3']  = cal_cor1( T3, yp_all, f_name, iter+1,  8)\n",
    "                        corr_results[set_name][f_name]['Tier4']  = cal_cor1(T4, yp_all, f_name, iter+1,  12)\n",
    "                        corr_results[set_name][f_name]['non-ADHD']  = cal_cor1(non, yp_all, f_name, iter+1, 16)\n",
    "                        corr_results[set_name][f_name]['All']  = cal_cor1(All, yp_all, f_name, iter+1, 20)\n",
    "                        # prediction_results = prediction_results.append(new_row, ignore_index=True)\n",
    "                        reshaped_row = new_row.values.reshape(1, -1)  # Reshape to a single row\n",
    "                        reshaped_row_df = pd.DataFrame(reshaped_row, columns=prediction_results.columns)\n",
    "                        prediction_results = pd.concat([prediction_results, reshaped_row_df], ignore_index=True)\n",
    "                        #pd.concat([prediction_results, pd.DataFrame([new_row], columns=prediction_results.columns)], ignore_index=True)\n",
    "            prediction_results.to_csv(plot_dir  + targ + model + '_abcd_predictive_ability.csv')\n",
    "            joblib.dump(corr_results, plot_dir  + targ + model + '_abcd_corr_res.joblib')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main: Stacked - ABCD + ABCC\n",
    "\n",
    "root_dir = '/media/hcs-sci-psy-narun/ABCC/fmriresults01/derivatives/ML_Tables/nesi_outputs/std_applicability/'\n",
    "\n",
    "targ_list = ['total_', 'cryst_','fluid_'] #'total_','fluid_'','fluid_', 'cryst_''total_'\n",
    "\n",
    "model_list = ['ntrf2']#,'pls','eN1''rf2''eN2',\n",
    "for model in model_list:\n",
    "      for targ in targ_list:\n",
    "            # model_outs = joblib.load(root_dir + targ + model + '.joblib')\n",
    "            # with open(root_dir + targ + model + 'rf2_output.pkl', 'rb') as f:\n",
    "            #       model_outs = pickle.load(f)\n",
    "            model_outs = joblib.load(root_dir + targ + model + '.joblib')\n",
    "            prediction_results = pd.DataFrame(columns=['', 'Tier1','Tier1','Tier1','Tier1','Tier2','Tier2','Tier2','Tier2',\n",
    "                                                                                                      'Tier3', 'Tier3', 'Tier3','Tier3', 'Tier4','Tier4', 'Tier4','Tier4', \n",
    "                                                                                                      'non-ADHD','non-ADHD','non-ADHD','non-ADHD', 'All', 'All','All','All'])\n",
    "            measure_list = ['Models','r', 'R2', 'MAE', 'RMSE', 'r', 'R2', 'MAE', 'RMSE', 'r', 'R2', 'MAE', 'RMSE','r', 'R2', 'MAE', 'RMSE','r', 'R2', 'MAE', 'RMSE','r', 'R2', 'MAE', 'RMSE']\n",
    "            prediction_results.loc[0] = measure_list\n",
    "            # r2_results = pd.DataFrame(['Tier1','Tier2', 'Tier3', 'Tier4', 'non-ADHD', 'All'], columns=['group'])\n",
    "            moda_yps = {'stacked': {}}\n",
    "            moda_yts = {'stacked': {}}\n",
    "            corr_results = {'stacked': {}}\n",
    "            plot_dict = {}\n",
    "            for fold, sets_dict in model_outs.items():\n",
    "                  for set_n, set_dict in sets_dict.items():\n",
    "                        for feature_n, feature_dict in set_dict.items():\n",
    "                              if feature_n not in moda_yps[set_n]:\n",
    "                                    moda_yps[set_n][feature_n] = []\n",
    "                                    moda_yts[set_n][feature_n] = []\n",
    "                              moda_yps[set_n][feature_n].append(feature_dict['data']['yptest'])\n",
    "                              moda_yts[set_n][feature_n].append(feature_dict['data']['yttest'])\n",
    "\n",
    "            for set_name , moda in moda_yps.items():\n",
    "                  for iter, (f_name, y) in enumerate(moda.items()):\n",
    "                        yp_all = pd.concat(y, axis=0)\n",
    "                        yt_all = pd.concat(moda_yts[set_name][f_name], axis=0)\n",
    "                        new_row = pd.Series([None] * len(prediction_results.columns), index=prediction_results.columns)\n",
    "                        corr_results[set_name][f_name] = {}\n",
    "                        corr_results[set_name][f_name]['Tier1'] = cal_cor1(T1, yp_all, f_name, iter+1, 0)\n",
    "                        corr_results[set_name][f_name]['Tier2']  = cal_cor1(T2, yp_all, f_name, iter+1, 4)\n",
    "                        corr_results[set_name][f_name]['Tier3']  = cal_cor1( T3, yp_all, f_name, iter+1,  8)\n",
    "                        corr_results[set_name][f_name]['Tier4']  = cal_cor1(T4, yp_all, f_name, iter+1,  12)\n",
    "                        corr_results[set_name][f_name]['non-ADHD']  = cal_cor1(non, yp_all, f_name, iter+1, 16)\n",
    "                        corr_results[set_name][f_name]['All']  = cal_cor1(All, yp_all, f_name, iter+1, 20)\n",
    "                        \n",
    "                        reshaped_row = new_row.values.reshape(1, -1)  # Reshape to a single row\n",
    "                        reshaped_row_df = pd.DataFrame(reshaped_row, columns=prediction_results.columns)\n",
    "                        prediction_results = pd.concat([prediction_results, reshaped_row_df], ignore_index=True)\n",
    "                        # prediction_results = prediction_results.append(new_row, ignore_index=True)\n",
    "                        pred_true = pd.concat([yp_all,yt_all], axis=1) \n",
    "                        #pred_true.to_csv(plot_dir  + targ + model + f_name +'_predictive_ability.csv')\n",
    "            prediction_results.to_csv(plot_dir  + targ + model + '_predictive_ability.csv')\n",
    "            joblib.dump(corr_results, plot_dir  + targ + model + '_corr_res.joblib')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lytle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WISC-II cognitive scores for each group \n",
    "adhd_cog2 = pd.read_csv('/media/hcs-sci-psy-narun/OpenNEURO_adhd/ds003500-download/derivatives/ML_Tables/cog_adhd2.csv', index_col=0)\n",
    "non_cog2 = pd.read_csv('/media/hcs-sci-psy-narun/OpenNEURO_adhd/ds003500-download/derivatives/ML_Tables/cog_non2.csv', index_col=0)\n",
    "all_cog2 = pd.read_csv('/media/hcs-sci-psy-narun/OpenNEURO_adhd/ds003500-download/derivatives/ML_Tables/cog.csv', index_col=0)\n",
    "\n",
    "adhd_cog2.index = adhd_cog2.index.str.replace('sub-', '')\n",
    "non_cog2.index = non_cog2.index.str.replace('sub-', '')\n",
    "all_cog2.index = all_cog2.index.str.replace('sub-', '')\n",
    "\n",
    "adhd_cog1 = pd.read_csv('/media/hcs-sci-psy-narun/OpenNEURO_adhd/ds002424-download/derivatives/ML_Tables/cog_adhd1.csv', index_col=0)\n",
    "non_cog1 = pd.read_csv('/media/hcs-sci-psy-narun/OpenNEURO_adhd/ds002424-download/derivatives/ML_Tables/cog_non1.csv', index_col=0)\n",
    "all_cog1 = pd.read_csv('/media/hcs-sci-psy-narun/OpenNEURO_adhd/ds002424-download/derivatives/ML_Tables/cog.csv', index_col=0)\n",
    "adhd_cog1.index = adhd_cog1.index.str.replace('sub-', '')\n",
    "non_cog1.index = non_cog1.index.str.replace('sub-', '')\n",
    "all_cog1.index = all_cog1.index.str.replace('sub-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate test performance measures and save them\n",
    "\n",
    "def cal_cor_t(group, all_predicted, key, i, col):\n",
    "    tar = targ[0:3]\n",
    "    group_pred_ind = list(set(all_predicted.index).intersection(group.dropna().index))\n",
    "\n",
    "    # true_val = group.loc[group_pred_ind].filter(like=tar, axis=1).values.flatten()\n",
    "    # yt_scaler = StandardScaler()\n",
    "    # yt_te_r = yt_all.values.reshape(-1, 1)\n",
    "    # syt_all = pd.DataFrame(y_scaler.transform(yt_te_r),  index=yt_all.index)\n",
    "    strue_val = yt_all.loc[group_pred_ind].values.flatten()\n",
    "    pre_val = all_predicted.loc[group_pred_ind].values.flatten()\n",
    "\n",
    "\n",
    "    p_corr, p_val = pearsonr(strue_val, pre_val)\n",
    "    r2 = r2_score(strue_val, pre_val)\n",
    "    # print(group.loc[group_pred_ind].filter(like=tar, axis=1).describe())\n",
    "    rmse = np.sqrt(mean_squared_error(strue_val, pre_val))\n",
    "    mae = mean_absolute_error(strue_val, pre_val)\n",
    "    # prediction_results = prediction_results.append(pd.Series(), ignore_index=True)\n",
    "    new_row[0] = key\n",
    "    new_row[col + 1] = round(p_corr, 3)\n",
    "    new_row[col + 2] = round(r2, 3)\n",
    "    new_row[col + 3] = round(rmse, 3)\n",
    "    new_row[col + 4] = round(mae, 3)\n",
    "    # plot_obj = plt.scatter(strue_val, pre_val)\n",
    "    plot_obj = [strue_val , pre_val]\n",
    "    boot_obj = [yt_all.loc[group_pred_ind], all_predicted.loc[group_pred_ind]]\n",
    "        # Calculate confidence interval for the correlation coefficient\n",
    "    # fisher_z = np.arctanh(p_corr)\n",
    "    # se = 1 / np.sqrt(len(group_pred_ind) - 3)\n",
    "    # z_score = norm.ppf(1 - (1 - 0.95) / 2)\n",
    "    # ci_lower_z = fisher_z - z_score * se\n",
    "    # ci_upper_z = fisher_z + z_score * se\n",
    "    # ci_lower = np.tanh(ci_lower_z)\n",
    "    # ci_upper = np.tanh(ci_upper_z)\n",
    "    ci_lower, ci_upper = bootstrap_corr_ci(strue_val, pre_val)\n",
    "\n",
    "    # plt.show()\n",
    "    plt.close('all')\n",
    "    return [plot_obj, r2, p_corr, len(group_pred_ind), boot_obj, [ci_lower, ci_upper]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main: Single - Lytle\n",
    "\n",
    "T22 =  pd.DataFrame()\n",
    "T32 =  pd.DataFrame()\n",
    "T42 =  pd.DataFrame()\n",
    "root_dir = '/media/hcs-sci-psy-narun/ABCC/fmriresults01/derivatives/ML_Tables/nesi_outputs/std_applicability/'\n",
    "targ_list = ['VIQ_', 'PIQ_', 'FSIQ_']\n",
    "model_list = ['enet1_output_fstd'] #'eN1', 'pls','pls',, 'pls1_output_fstd'\n",
    "test_set = '_op1'#\n",
    "\n",
    "for model in model_list:\n",
    "      for targ in targ_list:\n",
    "            print(targ)\n",
    "            model_outs = joblib.load(root_dir + targ +  model + test_set + '.joblib')\n",
    "\n",
    "            prediction_results = pd.DataFrame(columns=['Models', 'Tier1','Tier1','Tier1','Tier1','non-ADHD','non-ADHD','non-ADHD','non-ADHD', 'All', 'All','All','All'])\n",
    "            measure_list = ['Models','r', 'R2', 'MAE', 'RMSE', 'r', 'R2', 'MAE', 'RMSE', 'r', 'R2', 'MAE', 'RMSE']\n",
    "            prediction_results.loc[0] = measure_list\n",
    "            moda_yps = {'smri': {}, 'conn': {}, 'gtfc': {} ,'cntr': {}}\n",
    "            moda_yts = {'smri': {}, 'conn': {}, 'gtfc': {} ,'cntr': {}}\n",
    "            corr_results = {'smri': {}, 'conn': {}, 'gtfc': {} ,'cntr': {}}\n",
    "            plot_dict = {}\n",
    "            folds_results = {}\n",
    "            # for fold, sets_dict in model_outs.items():\n",
    "            nsets_dict= {\n",
    "                'smri': {key: model_outs[key] for key in ['cort', 'surf', 'subc', 'VolBrain']},\n",
    "                'conn': {key: model_outs[key] for key in ['verbal', 'spatial']},#\n",
    "                'gtfc': {key: model_outs[key] for key in ['tfc', 'gtfc']},\n",
    "                'cntr': {key: model_outs[key] for key in ['cntr_twoback_task-verbal', 'cntr_oneback_task-verbal', 'cntr_twoback-oneback_task-verbal', 'cntr_twoback_task-spatial', \n",
    "                                                            'cntr_oneback_task-spatial', 'cntr_twoback-oneback_task-spatial']} #\n",
    "                }\n",
    "\n",
    "            for set_n, set_dict in nsets_dict.items():\n",
    "                for  iter, (f_name, feature_dict) in enumerate(set_dict.items()):\n",
    "                        if f_name not in moda_yps[set_n]:\n",
    "                            moda_yps[set_n][f_name] = []\n",
    "                            moda_yts[set_n][f_name] = []\n",
    "                        yp_all = feature_dict['data']['yptest']\n",
    "                        yt_all = feature_dict['data']['yttest']\n",
    "                        #print(yp_all, yt_all)\n",
    "\n",
    "                        new_row = pd.Series([None] * len(prediction_results.columns), index=prediction_results.columns)\n",
    "                        corr_results[set_n][f_name] = {}\n",
    "                        corr_results[set_n][f_name]['ADHD'] = cal_cor_t(adhd_cog1, yp_all, f_name, iter+1, 0)\n",
    "\n",
    "                        corr_results[set_n][f_name]['non-ADHD']  = cal_cor_t(non_cog1, yp_all, f_name, iter+1, 4)\n",
    "                        corr_results[set_n][f_name]['All']  = cal_cor_t(all_cog1, yp_all, f_name, iter+1, 8)\n",
    "                        # prediction_results = prediction_results.append(new_row, ignore_index=True)\n",
    "\n",
    "                        reshaped_row = new_row.values.reshape(1, -1)  # Reshape to a single row\n",
    "                        reshaped_row_df = pd.DataFrame(reshaped_row, columns=prediction_results.columns)\n",
    "                        prediction_results = pd.concat([prediction_results, reshaped_row_df], ignore_index=True)\n",
    "                        # prediction_results = prediction_results.append(new_row, ignore_index=True)\n",
    "                        pred_true = pd.concat([yp_all,yt_all], axis=1) \n",
    "                        #pred_true.to_csv(plot_dir  + targ + model + f_name +'_predictive_ability.csv')\n",
    "\n",
    "            # prediction_results_grouped = prediction_results.loc[1:,:].groupby('Models').mean()\n",
    "            # prediction_results_grouped = pd.concat([new_row, prediction_results_grouped], ignore_index=True)\n",
    "            prediction_results.to_csv(plot_dir  + targ + model + test_set + '_predictive_ability.csv')\n",
    "            joblib.dump(corr_results, plot_dir  + targ + model + test_set + '_corr_res.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main: Stacked - Lytle\n",
    "\n",
    "adhd_cog = pd.read_csv('/media/hcs-sci-psy-narun/OpenNEURO_adhd/ds002424-download/derivatives/ML_Tables/cog_adhd1.csv', index_col=0)\n",
    "non_cog = pd.read_csv('/media/hcs-sci-psy-narun/OpenNEURO_adhd/ds002424-download/derivatives/ML_Tables/cog_non1.csv', index_col=0)\n",
    "all_cog = pd.read_csv('/media/hcs-sci-psy-narun/OpenNEURO_adhd/ds002424-download/derivatives/ML_Tables/cog.csv', index_col=0)\n",
    "adhd_cog.index = adhd_cog.index.str.replace('sub-', '')\n",
    "non_cog.index = non_cog.index.str.replace('sub-', '')\n",
    "all_cog.index = all_cog.index.str.replace('sub-', '')\n",
    "T22 =  pd.DataFrame()\n",
    "T32 =  pd.DataFrame()\n",
    "T42 =  pd.DataFrame()\n",
    "root_dir = '/media/hcs-sci-psy-narun/ABCC/fmriresults01/derivatives/ML_Tables/nesi_outputs/std_applicability/'\n",
    "targ_list = ['VIQ_', 'PIQ_', 'FSIQ_']\n",
    "test_set = '_op1' #'op2_'\n",
    "model_list = ['rf2_output_fstd']#\n",
    "\n",
    "for model in model_list:\n",
    "      for targ in targ_list:\n",
    "\n",
    "            model_outs = joblib.load(root_dir + targ +  model + test_set + '.joblib')\n",
    "            prediction_results = pd.DataFrame(columns=['Models', 'Tier1','Tier1','Tier1','Tier1','non-ADHD','non-ADHD','non-ADHD','non-ADHD', 'All', 'All','All','All'])\n",
    "            measure_list = ['Model','r', 'R2', 'MAE', 'RMSE', 'r', 'R2', 'MAE', 'RMSE', 'r', 'R2', 'MAE', 'RMSE']\n",
    "            prediction_results.loc[0] = measure_list\n",
    "           \n",
    "            moda_yps = {'stacked': {}}\n",
    "            moda_yts = {'stacked': {}}\n",
    "            corr_results = {'stacked': {}}\n",
    "            plot_dict = {}\n",
    "            folds_results = {}\n",
    "            # for fold, sets_dict in model_outs.items():\n",
    "            nmodel_outs = {'stacked': model_outs}       \n",
    "            for set_n, set_dict in nmodel_outs.items():\n",
    "                for  iter, (f_name, feature_dict) in enumerate(set_dict.items()):\n",
    "                        if f_name not in moda_yps[set_n]:\n",
    "                            moda_yps[set_n][f_name] = []\n",
    "                            moda_yts[set_n][f_name] = []\n",
    "                        yp_all = feature_dict['data']['yptest']\n",
    "                        yt_all = feature_dict['data']['yttest']\n",
    "                        #print(yp_all)\n",
    "                        new_row = pd.Series([None] * len(prediction_results.columns), index=prediction_results.columns)\n",
    "                        corr_results[set_n][f_name] = {}\n",
    "                        corr_results[set_n][f_name]['ADHD'] = cal_cor_t(adhd_cog, yp_all, f_name, iter+1, 0)\n",
    "\n",
    "                        corr_results[set_n][f_name]['non-ADHD']  = cal_cor_t(non_cog, yp_all, f_name, iter+1, 4)\n",
    "                        corr_results[set_n][f_name]['All']  = cal_cor_t(all_cog, yp_all, f_name, iter+1, 8)\n",
    "                        reshaped_row = new_row.values.reshape(1, -1)  # Reshape to a single row\n",
    "                        reshaped_row_df = pd.DataFrame(reshaped_row, columns=prediction_results.columns)\n",
    "                        prediction_results = pd.concat([prediction_results, reshaped_row_df], ignore_index=True)\n",
    "\n",
    "            # prediction_results_grouped = prediction_results.loc[1:,:].groupby('Models').mean()\n",
    "            # measure_list = pd.DataFrame([measure_list], columns=prediction_results.columns)\n",
    "            # prediction_results_grouped = pd.concat([measure_list, prediction_results_grouped], ignore_index=True)\n",
    "            prediction_results.to_csv(plot_dir + targ + model + test_set +  '_predictive_ability.csv')\n",
    "            joblib.dump(corr_results, plot_dir  + targ + model + test_set + '_corr_res.joblib')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
