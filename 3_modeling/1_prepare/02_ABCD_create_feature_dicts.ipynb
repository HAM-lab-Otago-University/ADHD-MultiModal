{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create Joblib dictionaries of features\n",
    "### separate objects for modalities and dataset source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farzane/anaconda3/envs/nilearn_py11/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dir = '/media/hcs-sci-psy-narun/ABCC/fmriresults01/derivatives/ML_Tables/'\n",
    "yue_dir = '/media/hcs-sci-psy-narun/ABCC/fmriresults01/derivatives/ML_Tables/structural_tables/Yue/'\n",
    "conn_dir = '/media/hcs-sci-psy-narun/ABCC/fmriresults01/derivatives/nilearn_glm/functional_tabels/'\n",
    "cntr_dir = '/media/hcs-sci-psy-narun/ABCC/fmriresults01/derivatives/nilearn_glm/functional_tabels/cntr/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ABCC & ABCD FC\n",
    "conn = {}\n",
    "conn.update({'conn_wm': pd.read_csv(conn_dir + 'task-nback_stat-pearsoncorrelation_desc-UncensoredFilteredFlat_Connectivity.csv', index_col=0)})\n",
    "conn.update({'conn_sst': pd.read_csv(conn_dir + 'task-SST_stat-pearsoncorrelation_desc-UncensoredFilteredFlat_Connectivity.csv', index_col=0)})\n",
    "conn.update({'conn_mid': pd.read_csv(conn_dir + 'task-MID_stat-pearsoncorrelation_desc-UncensoredFilteredFlat_Connectivity.csv', index_col=0)})\n",
    "conn.update({'conn_rest': pd.read_csv(conn_dir + 'task-rest_stat-pearsoncorrelation_desc-UncensoredFilteredFlat_Connectivity.csv', index_col=0)})\n",
    "conn.update({'subnet_rest': pd.read_csv(yue_dir + 'rsmri_subnet.csv', index_col=-3)})\n",
    "conn.update({'avg_rest': pd.read_csv(yue_dir + 'rsmri_within_avg_data.csv', index_col=-3)})\n",
    "\n",
    "FCs = {}\n",
    "FCs.update({'gfc': pd.read_csv(conn_dir + 'task-gfc_stat-pearsoncorrelation_desc-UncensoredFilteredFlat_Connectivity.csv', index_col=0)})\n",
    "FCs.update({'tfc': pd.read_csv(conn_dir + 'task-tfc_stat-pearsoncorrelation_desc-UncensoredFilteredFlat_Connectivity.csv', index_col=0)})\n",
    "\n",
    "#ABCC contrasts\n",
    "cntr_files = [file for file in os.listdir(cntr_dir) if file.endswith('.csv')]\n",
    "cntr = {}\n",
    "for cntr in cntr_files:\n",
    "    key = 'artr_' + cntr.split('_')[1][9:] + '_' + cntr.split('_')[0]  # adds the task name and contrast type e.g. nback, twoback\n",
    "    cntr.update({key: pd.read_csv(cntr_dir + cntr, index_col=0)})\n",
    "# ABCC sMRI\n",
    "abcc_smri ={\n",
    "    'cort':pd.read_csv(conn_dir+'stage 1_feature_tables/cortical_thickness.csv', index_col=0),\n",
    "    'subc':pd.read_csv(conn_dir+'stage 1_feature_tables/subcortical_volume.csv', index_col=0),\n",
    "    'surf':pd.read_csv(conn_dir+'stage 1_feature_tables/cortical_area.csv', index_col=0),\n",
    "    'VolBrain':pd.read_csv(conn_dir+'stage 1_feature_tables/total_brain_volume.csv', index_col=0)\n",
    "}\n",
    "\n",
    "abcc_smri.update({'T1_white': pd.read_csv(yue_dir + 'Avg_T1_White_.csv', index_col=-3)})\n",
    "abcc_smri.update({'T1_gray': pd.read_csv(yue_dir + 'Avg_T1_Gray_.csv', index_col=-3)})\n",
    "abcc_smri.update({'T2_white': pd.read_csv(yue_dir + 'Avg_T2_White_.csv', index_col=-3)})\n",
    "abcc_smri.update({'T2_gray': pd.read_csv(yue_dir + 'Avg_T2_Gray_.csv', index_col=-3)})\n",
    "abcc_smri.update({'Sulcal_Depth': pd.read_csv(yue_dir + 'Dest_Sulcal_Depth_.csv', index_col=-3)})\n",
    "abcc_smri.update({'T1_norm': pd.read_csv(yue_dir + 'Normalised_T1_.csv', index_col=-3)})\n",
    "abcc_smri.update({'T2_norm': pd.read_csv(yue_dir + 'Normalised_T2_.csv', index_col=-3)})\n",
    "abcc_smri.update({'T1_summ': pd.read_csv(yue_dir + 'smri_T1_mean_total_data.csv', index_col=-3)})\n",
    "abcc_smri.update({'T2_summ': pd.read_csv(yue_dir + 'smri_T2_mean_total_data.csv', index_col=-3)})\n",
    "abcc_smri.update({'DTI': pd.read_csv(yue_dir + 'DTI_data.csv', index_col=-2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 26\n"
     ]
    }
   ],
   "source": [
    "#other features from ABCD ready tables\n",
    "abcd_dir = '/media/hcs-sci-psy-narun/Yue/ABCD_5.1_data_precessing/processed_data/CSV/temp_far/'\n",
    "import os\n",
    "\n",
    "def get_csv_files(abcd_dir):\n",
    "    cntr_files = [file for file in os.listdir(abcd_dir) if file.endswith('.csv') and 'ROI' in file and file not in ['acspsw03_select.csv', 'Avg_T1_Gray_.csv', 'Avg_T1_White_.csv', 'Avg_T2_Gray_.csv', 'Avg_T2_White_.csv', 'cog_data.csv', 'demo_selected.csv', 'Dest_Sulcal_Depth_.csv', 'DTI_data.csv', 'NIH_TB_select.csv', 'Normalised_T1_.csv', 'Normalised_T2_.csv', 'rsmri_subnet.csv', 'smri_T1_mean_total_data.csv', 'smri_T2_mean_total_data.csv']]\n",
    "    rsmri_files = [file for file in os.listdir(abcd_dir) if file.endswith('.csv') and 'ROI' not in file and file not in ['acspsw03_select.csv', 'Avg_T1_Gray_.csv', 'Avg_T1_White_.csv', 'Avg_T2_Gray_.csv', 'Avg_T2_White_.csv', 'cog_data.csv', 'demo_selected.csv', 'Dest_Sulcal_Depth_.csv', 'DTI_data.csv', 'NIH_TB_select.csv', 'Normalised_T1_.csv', 'Normalised_T2_.csv', 'rsmri_subnet.csv', 'smri_T1_mean_total_data.csv', 'smri_T2_mean_total_data.csv']]\n",
    "\n",
    "    return cntr_files, rsmri_files\n",
    "\n",
    "cntr_files, rsmri_files = get_csv_files(abcd_dir)\n",
    "\n",
    "print(len(rsmri_files), len(cntr_files))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make sure they pass QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['eventname', 'imgincl_t1w_include', 'imgincl_t2w_include',\n",
       "       'imgincl_dmri_include', 'imgincl_rsfmri_include', 'imgincl_mid_include',\n",
       "       'imgincl_nback_include', 'imgincl_sst_include'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qc = pd.read_csv('/media/hcs-sci-psy-narun/abcd-data-release-5.1/core/imaging/mri_y_qc_incl.csv', index_col=0)\n",
    "new_ind_s = [ind.replace('_', '') for ind in qc.index]\n",
    "qc.index = new_ind_s\n",
    "qc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Unnamed: 0', 'SITE_ID_L', 'EVENTNAME']\n",
    "for iter, dict in enumerate([conn]): #, conn, cntr, FCs, abcc_smri     \n",
    "    print(iter)\n",
    "    for key in dict.keys():\n",
    "        print(len(dict[key].index))\n",
    "        #print(key, len(dict[key]))\n",
    "        if 'MID' in key or 'mid' in key:\n",
    "            qc_base_ind = qc[(qc['eventname'] == 'baseline_year_1_arm_1') & (qc['imgincl_mid_include']== 1)].index\n",
    "        elif 'SST' in key or 'sst' in key:\n",
    "            qc_base_ind = qc[(qc['eventname'] == 'baseline_year_1_arm_1') & (qc['imgincl_sst_include']== 1)].index\n",
    "        elif 'nback' in key or 'wm' in key:\n",
    "            qc_base_ind = qc[(qc['eventname'] == 'baseline_year_1_arm_1') & (qc['imgincl_nback_include']== 1)].index\n",
    "        elif 'rest' in key:\n",
    "            qc_base_ind = qc[(qc['eventname'] == 'baseline_year_1_arm_1') & (qc['imgincl_rsfmri_include']== 1)].index\n",
    "        elif 'DTI' in key:\n",
    "            qc_base_ind = qc[(qc['eventname'] == 'baseline_year_1_arm_1') & (qc['imgincl_dmri_include']== 1)].index\n",
    "            print(qc_base_ind, dict['DTI'].index)\n",
    "            dict['DTI']\n",
    "        elif 'T2' in key:\n",
    "            qc_base_ind = qc[(qc['eventname'] == 'baseline_year_1_arm_1') & (qc['imgincl_t2w_include']== 1)].index\n",
    "        else:\n",
    "            qc_base_ind = qc[(qc['eventname'] == 'baseline_year_1_arm_1') & (qc['imgincl_t1w_include']== 1)].index\n",
    "        # if iter == 0:\n",
    "        #     final_ind = qc_base_ind.intersection(set(list(dict[key].keys())))\n",
    "        #     for k in final_ind:\n",
    "        #         tang_dict[key].update({k : dict[key][k].values})\n",
    "        #         print(\"done\")\n",
    "        # else:\n",
    "        new_ind_s = [ind.replace('sub-', '') for ind in dict[key].index]\n",
    "        dict[key].index = new_ind_s\n",
    "        # Filter feature DataFrame based on final indices\n",
    "        if all(col in dict[key].columns for col in columns_to_drop):\n",
    "            dict[key] =  dict[key][(dict[key]['EVENTNAME'] == 'baseline_year_1_arm_1')]\n",
    "            dict[key].drop(columns=columns_to_drop, inplace=True)\n",
    "        final_ind = qc_base_ind.intersection(dict[key].index)  \n",
    "        print(len(final_ind))\n",
    "        new_df = dict[key].filter(items = final_ind, axis=0).copy()   \n",
    "        dict[key] = new_df  # Use .copy() to ensure it's a new DataFrame\n",
    "        print(key, len(dict[key]), len(new_df))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcd_cntr = {}\n",
    "columns_to_drop = ['Unnamed: 0', 'SITE_ID_L', 'EVENTNAME']\n",
    "\n",
    "for cntr in cntr_files:\n",
    "    key = cntr[:-4]\n",
    "    abcd_cntr.update({key: pd.read_csv(abcd_dir + cntr, index_col=-3)})\n",
    "    if 'mid' in key:\n",
    "        qc_base_ind = qc[(qc['eventname'] == 'baseline_year_1_arm_1') & (qc['imgincl_mid_include']== 1)].index\n",
    "    elif 'sst' in key:\n",
    "        qc_base_ind = qc[(qc['eventname'] == 'baseline_year_1_arm_1') & (qc['imgincl_sst_include']== 1)].index\n",
    "    else:\n",
    "        qc_base_ind = qc[(qc['eventname'] == 'baseline_year_1_arm_1') & (qc['imgincl_nback_include']== 1)].index\n",
    "    \n",
    "    new_ind_s = [ind.replace('_', '') for ind in abcd_cntr[key].index]\n",
    "    abcd_cntr[key].index = new_ind_s\n",
    "    # Filter feature DataFrame based on final indices\n",
    "    if all(col in abcd_cntr[key].columns for col in columns_to_drop):\n",
    "        abcd_cntr[key] =  abcd_cntr[key][(abcd_cntr[key]['EVENTNAME'] == 'baseline_year_1_arm_1')]\n",
    "        abcd_cntr[key].drop(columns=columns_to_drop, inplace=True)\n",
    "    final_ind = qc_base_ind.intersection(abcd_cntr[key].index)  \n",
    "    print(len(final_ind), len(abcd_cntr[key].index))\n",
    "    new_df = abcd_cntr[key].filter(items = final_ind, axis=0).copy()   \n",
    "    abcd_cntr[key] = new_df  # Use .copy() to ensure it's a new DataFrame\n",
    "    #print(key, len(abcd_cntr[key]), len(new_df))\n",
    "    #print(len(qc_base_ind))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11177 11668\n",
      "11177 11668\n",
      "11177 11668\n",
      "10471 11668\n",
      "11177 11668\n",
      "9299 11668\n",
      "11177 11668\n",
      "9299 11668\n"
     ]
    }
   ],
   "source": [
    "abcd_rsmri = {}\n",
    "columns_to_drop = ['Unnamed: 0', 'SITE_ID_L', 'EVENTNAME']\n",
    "\n",
    "for cntr in rsmri_files:\n",
    "    key = cntr[:-4]\n",
    "    abcd_rsmri.update({key: pd.read_csv(abcd_dir + cntr, index_col=-3)})\n",
    "    if 'rsmri' in key:\n",
    "        qc_base_ind = qc[(qc['eventname'] == 'baseline_year_1_arm_1') & (qc['imgincl_rsfmri_include']== 1)].index\n",
    "    elif 'T2' in key:\n",
    "        qc_base_ind = qc[(qc['eventname'] == 'baseline_year_1_arm_1') & (qc['imgincl_t2w_include']== 1)].index\n",
    "    else:\n",
    "        qc_base_ind = qc[(qc['eventname'] == 'baseline_year_1_arm_1') & (qc['imgincl_t1w_include']== 1)].index\n",
    "    \n",
    "    new_ind_s = [ind.replace('_', '') for ind in abcd_rsmri[key].index]\n",
    "    abcd_rsmri[key].index = new_ind_s\n",
    "    # Filter feature DataFrame based on final indices\n",
    "    if all(col in abcd_rsmri[key].columns for col in columns_to_drop):\n",
    "        abcd_rsmri[key] =  abcd_rsmri[key][(abcd_rsmri[key]['EVENTNAME'] == 'baseline_year_1_arm_1')]\n",
    "        abcd_rsmri[key].drop(columns=columns_to_drop, inplace=True)\n",
    "    final_ind = qc_base_ind.intersection(abcd_rsmri[key].index)  \n",
    "    print(len(final_ind), len(abcd_rsmri[key].index))\n",
    "    new_df = abcd_rsmri[key].filter(items = final_ind, axis=0).copy()   \n",
    "    abcd_rsmri[key] = new_df  # Use .copy() to ensure it's a new DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(abcc_smri, feature_dir + 'nesi_input_all/abcc_smri.joblib')\n",
    "joblib.dump(cntr, feature_dir + 'nesi_input_all/abcc_cntr.joblib')\n",
    "joblib.dump(conn, feature_dir + 'nesi_input_all/abcc_conn.joblib')\n",
    "joblib.dump(abcd_rsmri, feature_dir + 'nesi_input_all/abcd_smri.joblib')\n",
    "joblib.dump(abcd_cntr, feature_dir + 'nesi_input_all/abcd_cntr.joblib')\n",
    "joblib.dump(FCs, feature_dir + 'nesi_input_all/abcc_gtfc.joblib')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
